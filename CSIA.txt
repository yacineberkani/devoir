IA et cybersécurité : 8 cas d’usage principaux


intelligence et cybersécurité : 8 cas d'usage.
24 juillet 2020
L’Intelligence Artificielle (IA) est perçue par la plupart des spécialistes comme une avancée très profitable à notre société, permettant de prédire nos besoins et ainsi d’y répondre avec anticipation.
En matière de cybersécurité, la simple description de la situation actuelle des menaces dans le cyberespace suffit à comprendre l’intérêt que l’industrie porte à l’intelligence artificielle (IA). Sur le papier, l’IA, avec sa capacité à comprendre et analyser un contexte donné, peut contribuer à y détecter des anomalies ou des comportements inhabituels, révélateurs d’attaques et ainsi, à renforcer les outils de protection, détection, réponse et remédiation : augmentation du taux de détection, détection au plus tôt des attaques, amélioration de la capacité d’adaptation aux évolutions permanentes des SI.
1- L’IA intégrée aux équipements et applications de cybersécurité de l’infrastructure
Des technologies d’intelligence artificielle sont déjà intégrées dans des outils comme les anti-virus, les solutions EDR (Endpoint Detection and Response), les passerelles mail ou web, les firewalls, l’IAM, les CASB, les solutions DLP…, soit des équipements qui réagissent automatiquement aux attaques en filtrant le trafic malicieux. La plupart des éditeurs le font y compris en utilisant certaines technologies avancées telles que le deep learning (Google l’a intégré depuis 2015 pour filtrer les spams dans Gmail).
2- L’IA intégrée dans les sondes réseaux et autres Intrusion Detection Systems (IDS)
De nombreuses sondes intègrent des technologies d’IA, en complément de leur moteur de détection. La plupart de ces systèmes apprennent le comportement « normal » de l’infrastructure et toute déviation est remontée comme un signe d’un risque cyber. Les alertes remontées sont exploitées par des analystes, typiquement au sein d’un SOC, avec un taux de faux positifs non négligeable. L’ajout de ces technologies dans une infrastructure augmenter la charge de travail, tout en permettant de détecter plus d’attaques, ou de les détecter plus tôt. Un des enjeux est donc de mieux intégrer ces outils. Concrètement, la pertinence de ces technologies d’IA est d’autant plus grande qu’elles sont déployées dans les environnements où le trafic est relativement déterministe, tels que dans les environnements industriels.
3- L’IA pour détecter les comportements anormaux dans un SOC
Dans ce cas d’usage, l’IA est utilisée en parallèle ou en complément de la détection temps réel effectuée par exemple dans un SIEM : le système apprend du comportement standard de l’infrastructure ou des utilisateurs et mesure des écarts par rapport à ce comportement.
À la différence des sondes qui sont placées à un endroit précis de l’infrastructure, l’information récoltée par l’outil peut-être extrêmement hétérogène et provenir de multiples sources, ce qui accroit très sensiblement le niveau de difficulté. De fait, ces technologies paraissent aujourd’hui plus pertinentes en complément des outils classiques pour des environnements relativement stables et déterministes.
4- L’IA pour l’investigation des alertes et la recherche proactive de compromission (hunting) dans un SOC
Les analystes d’un SOC partent typiquement d’une alerte émanant d’un SIEM ou d’un autre outil pour ensuite en déterminer la criticité, l’étendue, l’urgence ainsi que les éléments techniques permettant de stopper les attaques et d’y remédier. Ils accèdent pour cela à un puits de données (data lake) où sont stockés les logs, des métadonnées de trafic ou autres informations. De plus ce puits de données peut être exploité pour rechercher des traces d’autres attaques qui n’auraient pas été détectées en temps réel. Cette activité s’appuie à la fois sur de l’expertise humaine et sur des outils (recherches d’observables, corrélation d’événements, etc.). L’intégration d’IA dans ces outils permet d’assister les experts pour qu’ils accèdent plus rapidement et facilement à la bonne information et pour qu’ils soient guidés dans leurs recherches.
5- L’IA appliquée à la réponse sur incident
Pour répondre aux incidents de cybersécurité, les équipes CERT ou CSIRT effectuent de nombreuses tâches qui peuvent en partie être automatisées : réinstallation d’anti-virus, vérification de clés de registre, modification de règles dans les firewalls, etc. Les plates-formes de réponse aux incidents (Security Orchestration and Automated Response – SOAR ou Security Incident Response Platform – SIRP) proposent des scénarios de réponse, automatiques ou semi-automatiques, afin de faciliter la sélection, l’exécution et l’enchainement des tâches. Certaines commencent également à intégrer des technologies d’IA afin d’assister plus efficacement les intervenants dans la sélection des actions à effectuer et d’augmenter l’automatisation.
6- L’IA appliquée au renseignement sur la menace (Threat Intelligence)
Le renseignement sur la menace consiste à collecter (typiquement sur le Web ou DarkWeb), un ensemble d’informations sur la menace et à les rendre opérationnelles : quels groupes d’attaquants sont actifs et pour faire quoi, avec quels modes opératoires, exploitant quelles vulnérabilités, à partir de quels serveurs web compromis de Command & Control… Plutôt que de se battre contre un ennemi invisible, il s’agit d’obtenir des renseignements sur lui pour mieux le contrer. Un des problèmes du renseignement sur la menace réside dans la capacité à fournir des informations pertinentes de manière structurée.
7- L’IA appliquée à la gestion des vulnérabilités
La gestion des vulnérabilités est devenue un point de tension pour les équipes opérationnelles, du fait de l’augmentation constante du nombre de failles connues, des difficultés à évaluer les risques réels induits et à prioriser et automatiser le déploiement des patchs. En effet, sur les milliers de vulnérabilités publiées tous les ans, seule une fraction est réellement utilisée par les attaquants. De plus, certains systèmes en sont protégés par des défenses périmétriques.
Cette complexité incite les fournisseurs d’outils de gestion des vulnérabilités à intégrer des technologies d’IA dans leurs solutions. L’objectif de l’IA appliquée à la gestion des vulnérabilités est d’améliorer la découverte des équipements déployés, le scan des vulnérabilités, la détermination des risques associés en lien avec l’intelligence sur la menace, la priorisation et le déploiement des patchs.
8- L’IA appliquée aux tests d’intrusions
Dans la même veine, et bien qu’il s’agisse à ce stade plus d’une vision ou de prototypes que de réalité, des travaux émanant de laboratoires universitaires, d’agences gouvernementales, d’entreprises établies ou de start-ups, visent à appliquer l’IA aux tests d’intrusions.
Ces tests nécessitent de trouver des vulnérabilités parmi de multiples possibles sur de nombreux systèmes, puis d’exploiter ces vulnérabilités par différentes techniques. L’arbre des choix possibles devient rapidement trop important pour être géré par un humain ou même parcouru automatiquement. Par ailleurs, l’analyse de la pratique des testeurs humains révèle qu’ils ont tendance à privilégier le parcours de l’arbre en profondeur plutôt qu’en largeur. Si technologies d’IA constituent un moyen de compenser les limites et contraintes des dispositifs actuels, plusieurs points d’attention doivent être pris en compte. L’IA ou plutôt le machine learning a surtout fait ses preuves dans la détection de fraudes, un domaine connexe à la cybersécurité. Ses bons résultats s’expliquent par le fait que l’on travaille depuis un certain temps sur des données normées. Aussi, elle ne peut être vue que comme un complément algorithmique aux outils existants.Si l’IA modifie le niveau d’expertise nécessaire à certaines activités de cybersécurité grâce l’automatisation des tâches à faible valeur ajoutée, il n’en reste pas moins que pour le moment l’IA ne diminue pas le besoin global d’expertise humaine. En effet les équipes doivent analyser plus d’évènements et de comportements suspects à partir de remontées qui difficiles à interpréter et qui nécessitent par conséquent des expertises de haut niveau. L’IA connaît également certaines limites morales voire légales car elle peut parfois prendre des décisions discutables d’un point de vue éthique et exploite souvent des données à caractère personnel.
Et surtout… Les systèmes de défense à base d’IA sont eux-mêmes vulnérables aux leurres que les attaquants mettent en place pour les contourner.
Les attaquants utilisent aussi des technologies d’IA pour augmenter leur potentiel de nuisance à moindre coût : pour sélectionner leurs cibles, optimiser leurs capacités d’intrusion (ex : phishing intelligent), déterminer les meilleures failles à exploiter (ex : scan de pages web intelligent), passer autant que possible sous le radar des systèmes de détection, etc. Par sa capacité à traiter de grands volumes de données, l’IA peut être vue comme un allié au service des défenseurs du cyberespace, en particulier pour détecter des menaces inconnues à condition toutefois d’être en capacité de traiter les faux positifs (et les faux négatifs ?). Mais elle peut aussi être mise à profit par les assaillants et leur permettre de développer des attaques intelligentes capables de s’adapter en temps réel aux réactions défensives.
La blockchain, l’IA ou le machine learning seront-ils les réponses que nous attendons tant ?
Là encore, il faut faire la part des choses. Ces technologies ne seront jamais des réponses aux questions qu’elles n’adressent pas. Elles permettront vraisemblablement de faire avancer les domaines de recherche, de créer de nouvelles offres, d’offrir une assistance aux parties prenantes, mais auront encore bien des difficultés à sécuriser ce que nous ne maîtrisons pas toujours.
